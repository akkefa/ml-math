{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices. The rows of the first matrix represent the latent user factors and the columns of the second matrix represent the latent item factors. The dot product of these two matrices approximates the original user-item interaction matrix. The latent factors are also known as embeddings and are typically of much lower dimensionality than the original user and item vectors. The latent factors are learned through an iterative process that minimizes the error between the dot product of the latent factors and the original user-item interaction matrix. The error is measured using a loss function such as mean squared error (MSE) or binary cross entropy (BCE). The loss function is minimized using gradient descent or one of its variants.\n",
    "\n",
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "So the singular value decomposition comes from linear algebra, and it's a way of breaking down a matrix into constituent parts. we can factorize it into three matrices. And this is called factorization because it works a lot like factoring numbers. You take 15, and you can factorize it into 3 and 5, such that you multiply 3 and 5 together, and you get 15.\n",
    "\n",
    "$$\n",
    "R=P \\Sigma Q^{\\mathrm{T}}\n",
    "$$\n",
    "\n",
    "- $R$ is $m \\times n$ ratings matrix\n",
    "- $P$ is $m \\times k$ user-feature affinity matrix\n",
    "- $Q$ is $n \\times k$ item-feature relevance matrix\n",
    "- $\\Sigma$ is $k \\times k$ diagonal feature weight matrix\n",
    "- For linear algebra people: $P$ and $Q$ are orthogonal\n",
    "- Linear algebra guarantees this exists for any real $R$\n",
    "\n",
    "\n",
    "### latent features\n",
    "\n",
    "Latent means not directly observable. The common use of the term in PCA and Factor Analysis is to reduce dimension of a large number of directly observable features into a smaller set of indirectly observable features.\n",
    "\n",
    "- SVD describes preference in terms of latent features\n",
    "- These features are learned from the rating data\n",
    "- Not necessarily interpretable\n",
    "    - Optimized for predictive power\n",
    "- Defines a shared vector space for users and items (feature space)\n",
    "    - Enables compact representation of each\n",
    "\n",
    "### Example using Superise library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data\n",
    "\n",
    "GroupLens Research has collected and made available rating data sets from the MovieLens web site (http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set.\n",
    "\n",
    "We are using Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018.\n",
    "\n",
    "Download: ml-latest-small.zip (size: 1 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (\"https://raw.githubusercontent.com/singhsidhukuldeep/Recommendation-System/master/data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "df.columns = ['userID', 'item', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  item  rating\n",
       "0       1     1     4.0\n",
       "1       1     3     4.0\n",
       "2       1     6     4.0\n",
       "3       1    47     5.0\n",
       "4       1    50     5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   userID  100836 non-null  int64  \n",
      " 1   item    100836 non-null  int64  \n",
      " 2   rating  100836 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100836, 3)\n",
      "-Dataset examples-\n",
      "        userID  item  rating\n",
      "0            1     1     4.0\n",
      "20000      132  1079     3.5\n",
      "40000      274  5621     2.0\n",
      "60000      387  6748     3.0\n",
      "80000      501    11     3.0\n",
      "100000     610  6978     4.0\n"
     ]
    }
   ],
   "source": [
    "print('Dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::20000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(100836, 3)\n",
      "The new data frame shape:\t(88364, 3)\n"
     ]
    }
   ],
   "source": [
    "# To reduce the dimensionality of the dataset, we will filter out rarely rated movies and rarely rating users.\n",
    "\n",
    "min_ratings = 5\n",
    "filter_items = df['item'].value_counts() > min_ratings\n",
    "filter_items = filter_items[filter_items].index.tolist()\n",
    "\n",
    "min_user_ratings = 5\n",
    "filter_users = df['userID'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "df_new = df[(df['item'].isin(filter_items)) & (df['userID'].isin(filter_users))]\n",
    "print('The original data frame shape:\\t{}'.format(df.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Surprise library\n",
    "\n",
    "To load a dataset from a pandas dataframe, we will use the load_from_df() method, we will also need a Reader object, and the rating_scale parameter must be specified. The dataframe must have three columns, corresponding to the user ids, the item ids, and the ratings in this order. Each row thus corresponds to a given rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_new[['userID', 'item', 'rating']], reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic algorithms\n",
    "\n",
    "With the Surprise library, we will benchmark the following algorithms\n",
    "\n",
    "\n",
    "##### NormalPredictor\n",
    "\n",
    "* NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal. This is one of the most basic algorithms that do not do much work.\n",
    "\n",
    "##### BaselineOnly\n",
    "\n",
    "* BasiclineOnly algorithm predicts the baseline estimate for given user and item.\n",
    "\n",
    "##### k-NN algorithms\n",
    "\n",
    "##### KNNBasic\n",
    "\n",
    "* KNNBasic is a basic collaborative filtering algorithm.\n",
    "\n",
    "##### KNNWithMeans\n",
    "\n",
    "* KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "\n",
    "##### KNNWithZScore\n",
    "\n",
    "* KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "\n",
    "##### KNNBaseline\n",
    "\n",
    "* KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "##### Matrix Factorization-based algorithms\n",
    "\n",
    "##### SVD\n",
    "\n",
    "* SVD algorithm is equivalent to Probabilistic Matrix Factorization (http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf)\n",
    "\n",
    "##### SVDpp\n",
    "\n",
    "* The SVDpp algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "\n",
    "##### NMF\n",
    "\n",
    "* NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD.\n",
    "\n",
    "##### Slope One\n",
    "\n",
    "* Slope One is a straightforward implementation of the SlopeOne algorithm. (https://arxiv.org/abs/cs/0702144)\n",
    "\n",
    "##### Co-clustering\n",
    "\n",
    "* Co-clustering is a collaborative filtering algorithm based on co-clustering (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&rep=rep1&type=pdf)\n",
    "\n",
    "\n",
    "We use rmse as our accuracy metric for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:  SVD\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.8591  0.8649  0.8654  0.8631  0.0028  \n",
      "Fit time          0.32    0.31    0.32    0.32    0.01    \n",
      "Test time         0.06    0.06    0.05    0.06    0.00    \n",
      "Done:  <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x128c69ed0> \n",
      "\n",
      "\n",
      "Starting:  KNNWithMeans\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.8664  0.8738  0.8656  0.8686  0.0037  \n",
      "Fit time          0.03    0.04    0.03    0.03    0.00    \n",
      "Test time         0.67    0.71    0.74    0.71    0.03    \n",
      "Done:  <surprise.prediction_algorithms.knns.KNNWithMeans object at 0x118f99290> \n",
      "\n",
      "\n",
      "Starting:  CoClustering\n",
      "Evaluating RMSE of algorithm CoClustering on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9202  0.9201  0.9141  0.9181  0.0028  \n",
      "Fit time          0.37    0.34    0.36    0.36    0.01    \n",
      "Test time         0.07    0.04    0.07    0.06    0.02    \n",
      "Done:  <surprise.prediction_algorithms.co_clustering.CoClustering object at 0x10e8378d0> \n",
      "\n",
      "\n",
      "\n",
      "\tDONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "\n",
    "# algorithms = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
    "algorithms = [SVD(), KNNWithMeans(), CoClustering()]\n",
    "# print (\"Attempting: \", str(algorithms), '\\n\\n\\n')\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    # print(\"Starting: \" ,str(algorithm))\n",
    "    print(\"Starting: \",str(algorithm).split(' ')[0].split('.')[-1])\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=True)\n",
    "    # results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp._append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    print(\"Done: \" ,str(algorithm), \"\\n\\n\")\n",
    "\n",
    "print ('\\n\\tDONE\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.863144</td>\n",
       "      <td>0.317520</td>\n",
       "      <td>0.056613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.868599</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.705638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.918101</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.062008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              test_rmse  fit_time  test_time\n",
       "Algorithm                                   \n",
       "SVD            0.863144  0.317520   0.056613\n",
       "KNNWithMeans   0.868599  0.033800   0.705638\n",
       "CoClustering   0.918101  0.356389   0.062008"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVDpp is performing best but it is taking a lot of time so we will use SED instean but apply GridSearch CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST RMSE: \t 0.8551825300121312\n",
      "BEST MAE: \t 0.6556891744787945\n",
      "BEST params: \t {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     \"n_epochs\": [5, 10, 15, 20, 30, 40, 50, 100],\n",
    "#     \"lr_all\": [0.001, 0.002, 0.005],\n",
    "#     \"reg_all\": [0.02, 0.08, 0.4, 0.6]\n",
    "# }\n",
    "\n",
    "# smaller grid for testing\n",
    "param_grid = {\n",
    "    \"n_epochs\": [10, 20],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.02]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], refit=True, cv=5)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "training_parameters = gs.best_params[\"rmse\"]\n",
    "\n",
    "print(\"BEST RMSE: \\t\", gs.best_score[\"rmse\"])\n",
    "print(\"BEST MAE: \\t\", gs.best_score[\"mae\"])\n",
    "print(\"BEST params: \\t\", gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n",
      "\n",
      "\n",
      "\t\t STARTING\n",
      "\n",
      "\n",
      "> Loading data...\n",
      "> OK\n",
      "> Creating trainset...\n",
      "> OK\n",
      "> Training...\n",
      "> OK \t\t It Took:  0 seconds\n",
      ">> DONE \t\t It Took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(training_parameters)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "print(\"\\n\\n\\t\\t STARTING\\n\\n\")\n",
    "start = datetime.now()\n",
    "\n",
    "print(\"> Loading data...\")\n",
    "data = Dataset.load_from_df(df_new[['userID', 'item', 'rating']], reader)\n",
    "print(\"> OK\")\n",
    "\n",
    "print(\"> Creating trainset...\")\n",
    "trainset = data.build_full_trainset()\n",
    "print(\"> OK\")\n",
    "\n",
    "\n",
    "startTraining = datetime.now()\n",
    "print(\"> Training...\")\n",
    "\n",
    "algo = SVD(n_epochs = training_parameters['n_epochs'], lr_all = training_parameters['lr_all'], reg_all = training_parameters['reg_all'])\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "endTraining = datetime.now()\n",
    "print(\"> OK \\t\\t It Took: \", (endTraining-startTraining).seconds, \"seconds\")\n",
    "\n",
    "end = datetime.now()\n",
    "print (\">> DONE \\t\\t It Took\", (end-start).seconds, \"seconds\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVING TRAINED MODEL\n",
    "# from surprise import dump\n",
    "# import os\n",
    "# model_filename = \"./model.pickle\"\n",
    "# print (\">> Starting dump\")\n",
    "# # Dump algorithm and reload it.\n",
    "# file_name = os.path.expanduser(model_filename)\n",
    "# dump.dump(file_name, algo=algo)\n",
    "# print (\">> Dump done\")\n",
    "# print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LOAD SAVED MODEL\n",
    "# def load_model(model_filename):\n",
    "#     print (\">> Loading dump\")\n",
    "#     from surprise import dump\n",
    "#     import os\n",
    "#     file_name = os.path.expanduser(model_filename)\n",
    "#     _, loaded_model = dump.load(file_name)\n",
    "#     print (\">> Loaded dump\")\n",
    "#     return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 610        item: 10         r_ui = None   est = 3.54   {'was_impossible': False}\n",
      "{'details': {'was_impossible': False},\n",
      " 'iid': '10',\n",
      " 'item': '10',\n",
      " 'rating': 3.543813091304151,\n",
      " 'true': None,\n",
      " 'uid': '610',\n",
      " 'user': '610'}\n",
      "\n",
      "\n",
      "\n",
      "{'user': '610', 'item': '10', 'rating': 3.543813091304151, 'details': {'was_impossible': False}, 'uid': '610', 'iid': '10', 'true': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "# model_filename = \"./model.pickle\"\n",
    "def itemRating(user, item):\n",
    "    uid = str(user)\n",
    "    iid = str(item) \n",
    "    # loaded_model = load_model(model_filename)\n",
    "    prediction = algo.predict(user, item, verbose=True)\n",
    "    rating = prediction.est\n",
    "    details = prediction.details\n",
    "    uid = prediction.uid\n",
    "    iid = prediction.iid\n",
    "    true = prediction.r_ui\n",
    "    ret = {\n",
    "        'user': user, \n",
    "        'item': item, \n",
    "        'rating': rating, \n",
    "        'details': details,\n",
    "        'uid': uid,\n",
    "        'iid': iid,\n",
    "        'true': true\n",
    "        }\n",
    "    pp (ret)\n",
    "    print ('\\n\\n')\n",
    "    return ret\n",
    "print(itemRating(user = \"610\", item = \"10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
