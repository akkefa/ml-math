{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network\n",
    "\n",
    "\n",
    "## Example 1\n",
    "\n",
    "Consider a simple neural network with one weight $ w $ and no bias. Let the input $ x $ and the actual output $ y $ be given. The prediction $ \\hat{y} $ is:\n",
    "\n",
    "$$ \\hat{y} = w \\cdot x $$\n",
    "\n",
    "The MSE loss function for a single data point is:\n",
    "\n",
    "$$ \\text{MSE} = (y - \\hat{y})^2 $$\n",
    "\n",
    "#### Step-by-Step Calculation\n",
    "\n",
    "1. **Prediction**: Compute the predicted output $ \\hat{y} $:\n",
    "\n",
    "   $$ \\hat{y} = w \\cdot x $$\n",
    "\n",
    "2. **Loss Calculation**: Compute the MSE loss:\n",
    "\n",
    "    $$ \\text{MSE} = (y - w \\cdot x)^2 $$\n",
    "\n",
    "   Let's take a numerical example to illustrate this process.\n",
    "\n",
    "   **Numerical Example:**\n",
    "   - Suppose $ x = 2 $, $ y = 5 $, and the current weight $ w = 1 $.\n",
    "\n",
    "   **Prediction**:\n",
    "\n",
    "   $$ \\hat{y} = 1 \\cdot 2 = 2 $$\n",
    "\n",
    "   **Loss Calculation**:\n",
    "\n",
    "   $$ \\text{MSE} = (5 - 2)^2 = 9 $$\n",
    "\n",
    "3. **Gradient Calculation**: Compute the partial derivative of the loss with respect to the weight $ w $:\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{\\partial}{\\partial w} (y - w \\cdot x)^2 $$\n",
    "\n",
    "   Using the chain rule:\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = 2 (y - w \\cdot x) \\cdot (-x) $$\n",
    "\n",
    "   Substitute the values from our example:\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = 2 (5 - 1 \\cdot 2) \\cdot (-2) $$\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = 2 (5 - 2) \\cdot (-2) $$\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = 2 \\cdot 3 \\cdot (-2) $$\n",
    "\n",
    "   $$ \\frac{\\partial \\text{MSE}}{\\partial w} = -12 $$\n",
    "\n",
    "4. **Update the Weight**: Use the gradient to update the weight $ w $ using gradient descent:\n",
    "   - Choose a learning rate $ \\eta $, typically a small positive number.\n",
    "   - Update rule: $ w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{MSE}}{\\partial w} $\n",
    "\n",
    "   **For example:**\n",
    "   - Suppose the learning rate $ \\eta = 0.1 $.\n",
    "\n",
    "   **Weight Update**:\n",
    "   \n",
    "   $$ w_{\\text{new}} = 1 - 0.1 \\cdot (-12) $$\n",
    "   $$ w_{\\text{new}} = 1 + 1.2 $$\n",
    "   $$ w_{\\text{new}} = 2.2 $$\n",
    "\n",
    "So, after one iteration of gradient descent with MSE loss, the updated weight $ w $ is $ 2.2 $.\n",
    "\n",
    "### Iterative Process\n",
    "\n",
    "This process repeats for each training sample during training:\n",
    "- Compute $ \\hat{y} $.\n",
    "- Calculate $ \\text{MSE} $.\n",
    "- Compute $ \\frac{\\partial \\text{MSE}}{\\partial w} $.\n",
    "- Update $ w $.\n",
    "\n",
    "Through multiple iterations (epochs), the network learns to minimize the MSE loss across all training samples, improving its ability to predict $ y $ from $ x $.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The gradient of the loss function (in this case, MSE) with respect to the weights of the network tells us how to adjust the weights to reduce the error between predicted and actual outputs during training. This iterative process is fundamental in training neural networks using gradient-based optimization algorithms like gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 9.0000, Updated weight: 2.2000, Y: 5.0000, Y_pred: 2.0000\n",
      "Gradients: -12.0000\n",
      "Epoch [2/5], Loss: 0.3600, Updated weight: 2.4400, Y: 5.0000, Y_pred: 4.4000\n",
      "Gradients: -2.4000\n",
      "Epoch [3/5], Loss: 0.0144, Updated weight: 2.4880, Y: 5.0000, Y_pred: 4.8800\n",
      "Gradients: -0.4800\n",
      "Epoch [4/5], Loss: 0.0006, Updated weight: 2.4976, Y: 5.0000, Y_pred: 4.9760\n",
      "Gradients: -0.0960\n",
      "Epoch [5/5], Loss: 0.0000, Updated weight: 2.4995, Y: 5.0000, Y_pred: 4.9952\n",
      "Gradients: -0.0192\n",
      "Final weight: 2.4995\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the input and output data (tensor form)\n",
    "x_data = torch.tensor([2.0])  # Input\n",
    "y_data = torch.tensor([5.0])  # Actual output\n",
    "\n",
    "# Define the model: Linear regression model with one weight parameter\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([1.0]))  # Weight parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w * x\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define the Mean Squared Error (MSE) loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Gradient Descent optimizer with learning rate 0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5  # Number of training epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss.backward()  # Compute gradients\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}, Updated weight: {model.w.item():.4f}, Y: {y_data.item():.4f}, Y_pred: {y_pred.item():.4f}')\n",
    "    # Print gradients\n",
    "    print(f'Gradients: {model.w.grad.item():.4f}')\n",
    "\n",
    "# After training, you can access the updated weight\n",
    "print(f'Final weight: {model.w.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
